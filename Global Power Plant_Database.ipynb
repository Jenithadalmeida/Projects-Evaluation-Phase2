{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29dd8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f39a2615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country country_long                      name   gppd_idnr  capacity_mw  \\\n",
      "0     IND        India          ACME Solar Tower  WRI1020239          2.5   \n",
      "1     IND        India       ADITYA CEMENT WORKS  WRI1019881         98.0   \n",
      "2     IND        India  AES Saurashtra Windfarms  WRI1026669         39.2   \n",
      "3     IND        India               AGARTALA GT  IND0000001        135.0   \n",
      "4     IND        India              AKALTARA TPP  IND0000002       1800.0   \n",
      "\n",
      "   latitude  longitude primary_fuel other_fuel1 other_fuel2  ...  \\\n",
      "0   28.1839    73.2407        Solar         NaN         NaN  ...   \n",
      "1   24.7663    74.6090         Coal         NaN         NaN  ...   \n",
      "2   21.9038    69.3732         Wind         NaN         NaN  ...   \n",
      "3   23.8712    91.3602          Gas         NaN         NaN  ...   \n",
      "4   21.9603    82.4091         Coal         Oil         NaN  ...   \n",
      "\n",
      "                     geolocation_source  wepp_id year_of_capacity_data  \\\n",
      "0  National Renewable Energy Laboratory      NaN                   NaN   \n",
      "1                                   WRI      NaN                   NaN   \n",
      "2                                   WRI      NaN                   NaN   \n",
      "3                                   WRI      NaN                2018.0   \n",
      "4                                   WRI      NaN                2018.0   \n",
      "\n",
      "  generation_gwh_2013 generation_gwh_2014 generation_gwh_2015  \\\n",
      "0                 NaN                 NaN                 NaN   \n",
      "1                 NaN                 NaN                 NaN   \n",
      "2                 NaN                 NaN                 NaN   \n",
      "3          631.777928          617.789264             843.747   \n",
      "4         1668.290000         3035.550000            5916.370   \n",
      "\n",
      "   generation_gwh_2016  generation_gwh_2017         generation_data_source  \\\n",
      "0                  NaN                  NaN                            NaN   \n",
      "1                  NaN                  NaN                            NaN   \n",
      "2                  NaN                  NaN                            NaN   \n",
      "3           886.004428           663.774500  Central Electricity Authority   \n",
      "4          6243.000000          5385.579736  Central Electricity Authority   \n",
      "\n",
      "   estimated_generation_gwh  \n",
      "0                       NaN  \n",
      "1                       NaN  \n",
      "2                       NaN  \n",
      "3                       NaN  \n",
      "4                       NaN  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the provided URL\n",
    "file_path = \"global_Power_plant_database.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec8505aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column before imputation:\n",
      "country                       0\n",
      "country_long                  0\n",
      "name                          0\n",
      "gppd_idnr                     0\n",
      "capacity_mw                   0\n",
      "latitude                     46\n",
      "longitude                    46\n",
      "primary_fuel                  0\n",
      "other_fuel1                 709\n",
      "other_fuel2                 907\n",
      "other_fuel3                 908\n",
      "commissioning_year          380\n",
      "owner                       566\n",
      "source                        0\n",
      "url                           0\n",
      "geolocation_source           19\n",
      "wepp_id                     908\n",
      "year_of_capacity_data       388\n",
      "generation_gwh_2013         524\n",
      "generation_gwh_2014         507\n",
      "generation_gwh_2015         483\n",
      "generation_gwh_2016         471\n",
      "generation_gwh_2017         465\n",
      "generation_data_source      458\n",
      "estimated_generation_gwh    908\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "print(\"Missing values in each column before imputation:\")\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbc57a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original numeric columns: ['capacity_mw', 'latitude', 'longitude', 'other_fuel3', 'commissioning_year', 'wepp_id', 'year_of_capacity_data', 'generation_gwh_2013', 'generation_gwh_2014', 'generation_gwh_2015', 'generation_gwh_2016', 'generation_gwh_2017', 'estimated_generation_gwh']\n",
      "Columns with all NaN values: ['other_fuel3', 'wepp_id', 'estimated_generation_gwh']\n",
      "Shape of imputed values: (908, 10)\n",
      "Missing values in each column after imputation:\n",
      "capacity_mw                 0\n",
      "latitude                    0\n",
      "longitude                   0\n",
      "commissioning_year          0\n",
      "year_of_capacity_data       0\n",
      "generation_gwh_2013         0\n",
      "generation_gwh_2014         0\n",
      "generation_gwh_2015         0\n",
      "generation_gwh_2016         0\n",
      "generation_gwh_2017         0\n",
      "country                     0\n",
      "country_long                0\n",
      "name                        0\n",
      "gppd_idnr                   0\n",
      "primary_fuel                0\n",
      "other_fuel1               709\n",
      "other_fuel2               907\n",
      "owner                     566\n",
      "source                      0\n",
      "url                         0\n",
      "geolocation_source         19\n",
      "generation_data_source    458\n",
      "dtype: int64\n",
      "Shape of final data after imputation: (908, 22)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Handle Missing Values\n",
    "\n",
    "# Identify numeric columns for imputation\n",
    "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "print(\"Original numeric columns:\", numeric_cols)\n",
    "\n",
    "# Check for columns with all NaN values\n",
    "all_nan_columns = data[numeric_cols].columns[data[numeric_cols].isnull().all()].tolist()\n",
    "print(\"Columns with all NaN values:\", all_nan_columns)\n",
    "\n",
    "# Use SimpleImputer to fill NaN values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Drop columns with all NaN values from numeric_cols before fitting the imputer\n",
    "valid_numeric_cols = [col for col in numeric_cols if col not in all_nan_columns]\n",
    "\n",
    "# Fit the imputer and transform only the valid numeric columns\n",
    "imputed_values = imputer.fit_transform(data[valid_numeric_cols])\n",
    "\n",
    "# Check the shape of the imputed values\n",
    "print(\"Shape of imputed values:\", imputed_values.shape)\n",
    "\n",
    "# Create a DataFrame from the imputed values with original numeric column names\n",
    "data_imputed = pd.DataFrame(imputed_values, columns=valid_numeric_cols)\n",
    "\n",
    "# Combine the imputed numeric data with the non-numeric columns\n",
    "non_numeric_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Rebuild the final DataFrame, ensuring to include all non-numeric columns\n",
    "data_final = pd.concat([data_imputed, data[non_numeric_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Confirm that there are no more missing values\n",
    "print(\"Missing values in each column after imputation:\")\n",
    "print(data_final.isnull().sum())\n",
    "\n",
    "# Check the shape of the final DataFrame\n",
    "print(f\"Shape of final data after imputation: {data_final.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e01f0739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final data after combining: (908, 22)\n",
      "Missing values in each column after combining:\n",
      "capacity_mw                 0\n",
      "latitude                    0\n",
      "longitude                   0\n",
      "commissioning_year          0\n",
      "year_of_capacity_data       0\n",
      "generation_gwh_2013         0\n",
      "generation_gwh_2014         0\n",
      "generation_gwh_2015         0\n",
      "generation_gwh_2016         0\n",
      "generation_gwh_2017         0\n",
      "country                     0\n",
      "country_long                0\n",
      "name                        0\n",
      "gppd_idnr                   0\n",
      "primary_fuel                0\n",
      "other_fuel1               709\n",
      "other_fuel2               907\n",
      "owner                     566\n",
      "source                      0\n",
      "url                         0\n",
      "geolocation_source         19\n",
      "generation_data_source    458\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combine the imputed numeric data with the non-numeric columns\n",
    "non_numeric_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "data_final = pd.concat([data_imputed, data[non_numeric_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Check the shape of the final DataFrame\n",
    "print(f\"Shape of final data after combining: {data_final.shape}\")\n",
    "\n",
    "# Check for missing values again after imputation\n",
    "print(\"Missing values in each column after combining:\")\n",
    "print(data_final.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b475422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for column in data_final.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data_final[column] = le.fit_transform(data_final[column].astype(str))\n",
    "    label_encoders[column] = le  # Save the encoder for later use if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c035904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      "primary_fuel\n",
      "1    207\n",
      "3    200\n",
      "6    102\n",
      "7     98\n",
      "2     55\n",
      "0     40\n",
      "5     17\n",
      "4      7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set class distribution:\n",
      "primary_fuel\n",
      "1    52\n",
      "3    50\n",
      "7    25\n",
      "6    25\n",
      "2    14\n",
      "0    10\n",
      "5     4\n",
      "4     2\n",
      "Name: count, dtype: int64\n",
      "Predicted class distribution:\n",
      "3    61\n",
      "1    57\n",
      "7    26\n",
      "6    25\n",
      "0     7\n",
      "2     5\n",
      "5     1\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.60      0.71        10\n",
      "           1       0.89      0.98      0.94        52\n",
      "           2       0.80      0.29      0.42        14\n",
      "           3       0.82      1.00      0.90        50\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       1.00      1.00      1.00        25\n",
      "           7       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.88       182\n",
      "   macro avg       0.67      0.61      0.62       182\n",
      "weighted avg       0.86      0.88      0.86       182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Training for Primary Fuel Prediction\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Split the data with stratification\n",
    "X_train_fuel, X_test_fuel, y_train_fuel, y_test_fuel = train_test_split(\n",
    "    X_fuel, y_fuel, test_size=0.2, random_state=42, stratify=y_fuel\n",
    ")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Training set class distribution:\")\n",
    "print(y_train_fuel.value_counts())\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(y_test_fuel.value_counts())\n",
    "\n",
    "# Create and fit the model\n",
    "rf_fuel = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "rf_fuel.fit(X_train_fuel, y_train_fuel)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_fuel = rf_fuel.predict(X_test_fuel)\n",
    "\n",
    "print(\"Predicted class distribution:\")\n",
    "print(pd.Series(y_pred_fuel).value_counts())\n",
    "\n",
    "# Calculating accuracy and generating classification report\n",
    "accuracy = accuracy_score(y_test_fuel, y_pred_fuel)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test_fuel, y_pred_fuel, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7a73925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.60      0.71        10\n",
      "           1       0.89      0.98      0.94        52\n",
      "           2       0.80      0.29      0.42        14\n",
      "           3       0.82      1.00      0.90        50\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       1.00      1.00      1.00        25\n",
      "           7       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.88       182\n",
      "   macro avg       0.67      0.61      0.62       182\n",
      "weighted avg       0.86      0.88      0.86       182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Step 8: Split the data into training and testing sets\n",
    "X_train_fuel, X_test_fuel, y_train_fuel, y_test_fuel = train_test_split(\n",
    "    X_fuel, y_fuel, test_size=0.2, random_state=42, stratify=y_fuel\n",
    ")\n",
    "\n",
    "# Create and fit the Random Forest model\n",
    "rf_fuel = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "rf_fuel.fit(X_train_fuel, y_train_fuel)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_fuel = rf_fuel.predict(X_test_fuel)\n",
    "\n",
    "# Calculating accuracy and generating classification report\n",
    "accuracy = accuracy_score(y_test_fuel, y_pred_fuel)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_test_fuel, y_pred_fuel, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "088b7249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to random_forest_fuel_prediction_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Importing joblib to save the model\n",
    "import joblib\n",
    "\n",
    "# Save the trained Random Forest model to a file\n",
    "model_filename = 'random_forest_fuel_prediction_model.joblib'\n",
    "joblib.dump(rf_fuel, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9853fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the file\n",
    "loaded_model = joblib.load(model_filename)\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "loaded_y_pred_fuel = loaded_model.predict(X_test_fuel)\n",
    "\n",
    "# Check the accuracy of the loaded model\n",
    "loaded_accuracy = accuracy_score(y_test_fuel, loaded_y_pred_fuel)\n",
    "print(f\"Loaded model accuracy: {loaded_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "948e844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained Random Forest model\n",
    "joblib.dump(rf_fuel, 'random_forest_fuel_model.pkl')\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95be5574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from the loaded model: [7 1 0 7 3 1 3 7 3 6 1 3 3 1 1 3 1 3 1 6 7 7 7 7 6 7 7 7 7 1 3 3 1 1 1 3 5\n",
      " 1 2 1 0 6 3 1 1 1 3 3 7 3 3 7 3 1 6 3 3 1 3 6 6 3 1 3 7 3 7 3 3 3 1 3 0 7\n",
      " 3 1 6 1 1 3 3 3 3 3 1 3 3 6 6 1 3 3 2 7 3 3 6 0 1 3 7 3 1 7 2 6 3 7 1 7 1\n",
      " 1 3 3 1 0 1 6 1 6 1 0 3 1 1 1 6 1 3 1 1 3 3 3 1 7 3 2 1 3 3 6 3 1 1 6 3 0\n",
      " 6 1 1 7 3 6 1 6 7 1 3 1 1 1 3 7 3 6 6 6 1 1 2 3 6 1 1 3 1 6 3 1 7 3]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = joblib.load('random_forest_fuel_model.pkl')\n",
    "\n",
    "# You can use the loaded model to make predictions\n",
    "y_pred_loaded = loaded_model.predict(X_test_fuel)\n",
    "print(\"Predictions from the loaded model:\", y_pred_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be370e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
